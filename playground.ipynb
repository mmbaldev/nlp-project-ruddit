{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mehdi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/mehdi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/ruddit.csv')\n",
    "sentences = dataset['comment_text']\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset['comment_text'], dataset['offensiveness_score'], train_size=0.75, test_size=0.25, random_state=0)\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_corpus(corpus):\n",
    "    tokenized_clean_docs = []\n",
    "    cleaned_docs = []\n",
    "    for doc in corpus:\n",
    "        text_data = re.sub('[^a-zA-Z]', ' ', doc)\n",
    "        text_data = text_data.lower()\n",
    "        text_data = text_data.split()\n",
    "        wl = WordNetLemmatizer()\n",
    "        # text_data = [wl.lemmatize(word) for word in text_data if not word in set(stopwords.words('english'))]\n",
    "        text_data = ' '.join(text_data)\n",
    "        cleaned_docs.append(text_data)\n",
    "        tokenized_clean_docs.append(word_tokenize(text_data))\n",
    "\n",
    "    cleaned_docs = pd.Series(cleaned_docs)\n",
    "    return cleaned_docs, tokenized_clean_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cleaned, x_train_tokenized = clean_corpus(x_train)\n",
    "x_test_cleaned, x_test_tokenized = clean_corpus(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "# Use the fit_transform method to transform the sentences into a bag of words\n",
    "bow = vectorizer.fit_transform(cleaned_sentences)\n",
    "# Print the vocabulary (features) of the bag of words\n",
    "print(vectorizer.get_feature_names())\n",
    "# Print the bag of words\n",
    "print(bow.toarray())\n",
    "print(bow.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Use the fit_transform method to transform the documents into a TF-IDF matrix\n",
    "tfidf = vectorizer.fit_transform(sentences)\n",
    "# Print the vocabulary (features) of the TF-IDF matrix\n",
    "print(vectorizer.get_feature_names())\n",
    "# Print the TF-IDF matrix\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the dataset for a w2v model using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api \n",
    "\n",
    "w2v = Word2Vec(tokenized_clean_sentences, min_count=1,vector_size=300)\n",
    "\n",
    "print(w2v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads gensim pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(api.info()['models'].keys()))\n",
    "w2vec_google_news_model = api.load('word2vec-google-news-300')\n",
    "glove_twitter_model = api.load('glove-twitter-200')\n",
    "fasttext_wiki_news_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that are not in the embedding model vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_not_in_vocab(sentences_tokens, w2v_model):\n",
    "    not_in_words = []\n",
    "    for sentence_tokens in sentences_tokens:\n",
    "        for word in sentence_tokens:\n",
    "            if word not in w2v_model and word not in not_in_words:\n",
    "                not_in_words.append(word)\n",
    "    return not_in_words\n",
    "\n",
    "print(len(words_not_in_vocab(tokenized_clean_sentences, w2vec_google_news_model)))\n",
    "print(len(words_not_in_vocab(tokenized_clean_sentences, glove_twitter_model)))\n",
    "print(len(words_not_in_vocab(tokenized_clean_sentences, fasttext_wiki_news_model)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrain the fasttext model with vocabularies that are not existed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vectorize method for calculate the w2v of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence_tokens, w2v_model, vector_size=300):\n",
    "    words_vecs = [w2v_model[word] for word in sentence_tokens if word in w2v_model]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vectorized = ([vectorize(tokens, fasttext_wiki_news_model) for tokens in x_train_tokenized])\n",
    "x_test_vectorized = ([vectorize(tokens, fasttext_wiki_news_model) for tokens in x_test_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(x_train_vectorized, y_train)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(x_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "svr_reg = SVR(kernel = 'rbf')\n",
    "svr_reg.fit(x_train_vectorized, y_train)\n",
    "\n",
    "mlp_reg = MLPRegressor(random_state=1, max_iter=500)\n",
    "mlp_reg.fit(x_train_vectorized, y_train)\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(x_train_vectorized, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def model_inference(sentence, model):\n",
    "    tokens = sentence.split()\n",
    "    sentence_embedding = vectorize(tokens, fasttext_wiki_news_model)\n",
    "    return model.predict([sentence_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = clf.predict(x_test_vectorized)\n",
    "svr_preds = svr_reg.predict(x_test_vectorized)\n",
    "linear_preds = linear_reg.predict(x_test_vectorized)\n",
    "mlp_preds = mlp_reg.predict(x_test_vectorized)\n",
    "rf_preds = rf_reg.predict(x_test_vectorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report\n",
    "SVR_MAE = mean_absolute_error(y_test, svr_preds)\n",
    "SVR_MSE = mean_squared_error(y_test, svr_preds)\n",
    "REG_MAE = mean_absolute_error(y_test, linear_preds)\n",
    "REG_MSE = mean_squared_error(y_test, linear_preds)\n",
    "MLP_MAE = mean_absolute_error(y_test, mlp_preds)\n",
    "MLP_MSE = mean_squared_error(y_test, mlp_preds)\n",
    "RF_MAE = mean_absolute_error(y_test, rf_preds)\n",
    "RF_MSE = mean_squared_error(y_test, rf_preds)\n",
    "\n",
    "print(f\"SVR MAE score is: {SVR_MAE}\")\n",
    "print(f\"SVR MSE score is: {SVR_MSE}\")\n",
    "print(svr_reg.score(x_test_vectorized, y_test))\n",
    "print(f\"REG MAE score is: {REG_MAE}\")\n",
    "print(f\"REG MSE score is: {REG_MSE}\")\n",
    "print(linear_reg.score(x_test_vectorized, y_test))\n",
    "print(f\"MLP MAE score is: {MLP_MAE}\")\n",
    "print(f\"MLP MSE score is: {MLP_MSE}\")\n",
    "print(mlp_reg.score(x_test_vectorized, y_test))\n",
    "print(f\"RF MAE score is: {RF_MAE}\")\n",
    "print(f\"RF MSE score is: {RF_MSE}\")\n",
    "print(rf_reg.score(x_test_vectorized, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.plot(y_test[:100])\n",
    "plt.plot(svr_preds[:100])\n",
    "plt.plot(linear_preds[:100])\n",
    "plt.plot(mlp_preds[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_inference(\"youre fucking nice \", regressor)\n",
    "# for index, pred in enumerate(svr_preds):\n",
    "    # if (pred - y_test[index])**2 > 0.5:\n",
    "    #     print(x_test[index], pred, y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Prepreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      object\n",
      "score    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/ruddit.csv')\n",
    "x_train, x_test_valid, y_train, y_test_valid = train_test_split(dataset[\"comment_text\"], dataset['offensiveness_score'] , train_size=0.8, test_size=0.2, random_state=0)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test_valid, y_test_valid, test_size=0.5, random_state=0)\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "x_valid = x_valid.reset_index(drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)\n",
    "train = pd.DataFrame({'text': x_train, 'score': y_train})\n",
    "test = pd.DataFrame({'text': x_test, 'score': y_test})\n",
    "valid = pd.DataFrame({'text': x_valid, 'score': y_valid})\n",
    "train['score'] = train['score'].astype('float32')\n",
    "test['score'] = test['score'].astype('float32')\n",
    "valid['score'] = valid['score'].astype('float32')\n",
    "print(valid.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mehdi/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mehdi/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BASE_MODEL = \"bert-base-cased\"\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train['text']), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(valid['text']), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test['text']), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class RudditDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = RudditDataset(train_encodings, train['score'])\n",
    "val_dataset = RudditDataset(val_encodings, valid['score'])\n",
    "test_dataset = RudditDataset(test_encodings, test['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "    \n",
    "    # Compute accuracy \n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/fine-tuned-regression-1\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7bff233f224a21bf155209d49ff8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f73b63dbf14f359e9a737203429272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.030178766697645187, 'eval_mse': 0.030178766697645187, 'eval_mae': 0.1319590061903, 'eval_r2': 0.7650108361277528, 'eval_accuracy': 0.9911347517730497, 'eval_runtime': 68.5199, 'eval_samples_per_second': 8.231, 'eval_steps_per_second': 0.525, 'epoch': 1.0}\n",
      "{'loss': 0.0433, 'learning_rate': 2.269503546099291e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b1eebc809144bc8eb7a6fee62d0eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.027695482596755028, 'eval_mse': 0.027695482596755028, 'eval_mae': 0.1253727823495865, 'eval_r2': 0.7843471120679827, 'eval_accuracy': 0.9893617021276596, 'eval_runtime': 78.2377, 'eval_samples_per_second': 7.209, 'eval_steps_per_second': 0.46, 'epoch': 2.0}\n",
      "{'train_runtime': 4225.7312, 'train_samples_per_second': 2.133, 'train_steps_per_second': 0.133, 'train_loss': 0.041004494360998164, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=564, training_loss=0.041004494360998164, metrics={'train_runtime': 4225.7312, 'train_samples_per_second': 2.133, 'train_steps_per_second': 0.133, 'train_loss': 0.041004494360998164, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3e7f8489414e158fdaca80a2906e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.032084871083498,\n",
       " 'eval_mse': 0.032084871083498,\n",
       " 'eval_mae': 0.13935185968875885,\n",
       " 'eval_r2': 0.7126925165259967,\n",
       " 'eval_accuracy': 0.9875666074600356,\n",
       " 'eval_runtime': 77.3045,\n",
       " 'eval_samples_per_second': 7.283,\n",
       " 'eval_steps_per_second': 0.466,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_dataset=test_dataset\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
